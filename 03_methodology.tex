\chapter{METHODOLOGY}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{Figures/FlowofMethodology.png}
    \caption{Methodology Flowchart}
    \label{fig:Methodology}
\end{figure}

Figure \ref{fig:Methodology} shows an overview of the methodology for this study. Posts collected will first be annotated according to their sentiment, and then used to fine-tune the model. Posts will then be used as a basis of the environment of our simulation, whilst the sentiments extracted by XLM-R will be used to define our agents. The agent-based model will then simulate interactions made regarding electoral candidates, which may or may not trigger a change in the user’s views and attitudes.

\section{Data Collection}
Due to the discontinuation of the official free Academic API from X, the researchers will have to use a third-party Application Programming Interface (API) called Twikit for scraping posts about the 2022 Philippine Presidential elections. In collecting posts, keywords and dates will be utilized to perform an advanced search to get the posts needed for the analysis.\newline

\begin{table}[h]
    \renewcommand{\arraystretch}{1.8}

    \caption{Table for Philippine Dataset Ranges}
    \centering
    \begin{tabularx}{\textwidth}{>{\centering\arraybackslash}p{4cm}|>{\centering\arraybackslash}p{5cm}|>{\centering\arraybackslash}p{5cm}}
        \textbf{Election Year} & \textbf{Start Date (Deadline for Filing of CoC)} & \textbf{End Date (Election Day Proper)}\\
        \hline\hline
        2019 Midterm & October 17, 2018 & May 12, 2019 \\
        \hline
        2022 Presidential & October 8, 2021 & May 8, 2022 \\
        \hline
        2025 Midterm & October 8, 2024 & May 11, 2025 \\
    \end{tabularx}
\end{table}

The rationale behind the inclusive start-end dates is the high likelihood of a spike in sentiments from the public in two major events: the finalization of official candidates and election day proper.

Posts scraped per query will be saved in a CSV file with relevant information about each post, such as the account that posted it, engagement metrics (e.g. likes, replies, reposts), and whether or not the post is a standalone post, a reply to a prior existing post, or a quote repost of another post. 

\section{Data Preprocessing}
Before a group of datasets is fed into a tokenizer, they will undergo text processing.  Stop words such as “the,” “a,” “is”, etc., will not be removed as they might be considered for the full context of a sentence when performing byte-tokenization. The following steps to preprocess the data will be as follows:

\begin{itemize}
    \item Omitting a post from the dataset if it is not in English, Tagalog, or a mix of them. Since Twikit takes care of labeling languages during the collection, they can be filtered using the Python library Pandas.
    \item Removing punctuation marks that have no significance for sentiment analysis.
    \item Replacing emojis with special tags.
    \item Removing unnecessary emojis or replacing emojis with special tags describing them if it is necessary for sentiment analysis.
    \item Lowercasing the text.
    \item Handling links and email addresses by replacing them with a placeholder.
    \item Removing whitespaces and replacing multiple spaces with a single space.
    \item Adding paddings to equalize the length of sentences.
    \item Anonymize the user mentions by replacing them with @user except for candidates’ user handles, if this is present in the post.
\end{itemize}

The preprocessed dataset will be placed in a new CSV file. It is expected that the dataset, after they are preprocessed, will be 20,000 posts per election.

\section{Text Annotation}
\subsection{XLM-RoBERTa}
To detect the sentiment of election posts, they will be manually annotated as positive, negative, or neutral. Each has a value of 0, 1, and 2, respectively, once it is converted for analysis. These labels will help build the model dedicated to this study by adding a classification layer.

\begin{table}[h]
    \renewcommand{\arraystretch}{1.8}

    \caption{Sample Sentiment Annotation}
    \centering
    \begin{tabularx}{\textwidth}{>{\centering\arraybackslash}p{4cm}|>{\centering\arraybackslash}p{10cm}}
        \textbf{Positive} & "Showing my support to a good friend and Bagumbayan candidate for Senator Rafael Acuman" \\
        \hline
        \textbf{Neutral} & "A total of 129 party-list groups have filed their Certificate of Nomination and Acceptance CONA so far COMELEC expects a hundred more last-minute filers today." \\
        \hline
        \textbf{Negative} & “Mayoral candidate Isko Moreno blames incumbent Mayor Joseph Estrada for the worsening state of Manila adding that he will never build a political dynasty if he wins” \\
    \end{tabularx}
\end{table}

Pre-existing XLM-R models that are already capable of determining sentiments of posts on X will be used. For this study, Anke et al.’s \cite{Barbieri-2022} XLM-T-Base model will be employed, with additional fine-tuning to accurately detect Filipino and English election sentiments while keeping the general sentiments. The 2019 and 2022 election datasets will be used to train sentiments, while the 2025 dataset will serve as an evaluation dataset. The metrics to be used will be:
\begin{itemize}
    \item Accuracy for overall correctness
    \item Precision, Recall, and F1-score, especially when the dataset is imbalanced 
    \item A Confusion Matrix to determine the misclassification during the evaluation process
\end{itemize}

A dataset of posts with hashtags \#Eleksyon[Year] and \#Halalan[Year] will be used for fine-tuning.

\begin{table}[h]
    \renewcommand{\arraystretch}{1.8}

    \caption{Number of Tweets to Feed for Fine-Tuning}
    \centering
    \begin{tabularx}{\textwidth}{>{\centering\arraybackslash}p{3cm}|>{\centering\arraybackslash}p{4cm}|>{\centering\arraybackslash}p{4cm}|>{\centering\arraybackslash}p{4cm}}
        \multirow{2}{*}{\textbf{Year}} & \multicolumn{3}{c}{\textbf{Sentiments}} \\
        & \textbf{Positive} & \textbf{Neutral} & \textbf{Negative} \\
        \hline\hline
        2019 & 118 & 2498 & 120 \\
        \hline
        2022 & 126 & 3642 & 245 \\
        \hline
        2025 & 149 & 1155 & 178 \\
        \hline
        \textbf{TOTAL} & \textbf{393} & \text{7295} & \textbf{543} \\
    \end{tabularx}
    
\end{table}

The proportion of the three sentiments is significantly uneven. To prevent the model from dominantly inferring neutral sentiment, it will use Focal Loss instead of Cross Entropy Loss (CEL) to address the class imbalances, which uses a modified version of CEL with additional parameters such as \(\gamma\) (focusing factor) and optionally \(\alpha\) (class weight) to put more emphasis on the classes that are difficult to classify \cite{Lin-2018}.

\subsection{Preparation for Fine-Tuning}
\begin{table}[h]
    \renewcommand{\arraystretch}{1.8}

    \caption{Hyperparameters for Fine-Tuning Anke et al.'s \cite{Barbieri-2022} Twitter-XLM-RoBERTa-Base using Election  Tweets}
    \centering
    \begin{tabularx}{\textwidth}{>{\centering\arraybackslash}p{9cm}|>{\centering\arraybackslash}p{5cm}}
        \textbf{Hyperparameter} & \textbf{Value} \\
        \hline\hline
        Epochs & 3 \\
        \hline
        Train Batch Size per Device & 16 \\
        \hline
        Evaluation Batch Size per Device & 32 \\
        \hline
        Learning Rate & 2e-5 \\
        \hline
        Weight Decay Rate & 0.01 \\
        \hline
        Warm-up Steps & 0.06 \\
    \end{tabularx}
    \label{fig:hyperparameters}
    
\end{table}

Table \ref{fig:hyperparameters} shows the hyperparameters that will be used to fine-tune the model. First, three epochs are used to train and evaluate the model. Then, the learning rate is set at 2e-5, which differs from some models that use a rate of 5e-5, as this model is being fine-tuned from a pre-trained version. Then, batch sizes for training and evaluation differ to accelerate the evaluation process. Lastly, the weight decay rate is set at 0.01 and the warmup ratio is 0.06.

\section{Agent-Based Modeling}
\subsection{Creating the baseline simulation: 2019 Midterm and 2022 Presidential Elections}
The output of the fine-tuned XLM-R model serves as a foundation for the creation of an agent. The following are the categories an agent belongs to: candidates, news outlets mentioning the candidates, influencers, and the general public. Influencer agents are neither candidates nor news outlets, yet they have more average interactions in their tweets than the general public. Therefore, they can serve as a “seed” in the simulation process.

\subsection{Changing State}
To change state, agents must interact with other agents and the relevant issues occurring during a specific time period.  Therefore, the following events in Table \ref{tab:debates} during the election have the potential to cause spikes in sentiments.

\clearpage

\begin{table}[h]
    \renewcommand{\arraystretch}{1.8}

    \caption{Table of Debates}
    \centering
    \begin{tabularx}{\textwidth}{>{\centering\arraybackslash}p{4cm}|>{\centering\arraybackslash}p{4.5cm}|>{\centering\arraybackslash}p{5.5cm}}
        \textbf{Election Year} & \textbf{Key Dates} & \textbf{Events}\\
        \hline\hline
        \multirow{4}{*}{2019 Midterm} & February 9, 2019 & GMA Network's Senatorial Face-Off \\
        & February 18, 2019 & ABS-CBN's Harapan 2019 (1st Senatorial Town Hall Debate) \\
        & March 1, 2019 & ABS-CBN's Harapan 2019 (2nd Senatorial Town Hall Debate) \\
        & April 26, 2019 & CNN Philippines Senatorial Debate at UST \\
        \hline
        \multirow{4}{*}{2022 Presidential} & February 15, 2022 & SMNI Presidential Debate \\
        & February 26, 2022 & CNN Philippines Vice Presidential Debate \\
        & March 19, 2022 & COMELEC PiliPinas Presidential Debate (1st) \\
        & March 20, 2022 & COMELEC PiliPinas Vice Presidential Debate \\
        \hline
        2025 Midterm & \multicolumn{2}{p{\textwidth}}{No COMELEC-hosted debates in this election year \cite{Aning-2025}.} \\
    \end{tabularx}
    \label{tab:debates}
\end{table}

To mitigate the lack of debates during the 2025 elections, key issues and surveys during the last three elections can factor into how the agents will react towards them. These terms are picked to ensure impartiality.
\begin{itemize}
    \item Surveys (such as Pulse Asia)
    \item Issues: corruption, infrastructure, inflation, disinformation, fake news
\end{itemize}

\subsection{Simulating the 2025 Midterm Elections}
Using the calibrated 2019 and 2022 elections simulation, the succeeding 2025 midterm election can now be simulated. Posts will be gathered about the 2025 midterms elections for the top 20 winning candidates. Sentiments from those posts will be extracted, and then fed as input into the simulation. The simulation will then determine election results. To verify the accuracy of these simulated results, t-testing will be done to determine if there is any statistically significant differences between simulated voter proportions and actual voter proportions during the 2025 midterm elections. 

\subsection{Predicting Future Presidential Elections}
Once the simulation has been verified to have accurately predicted the 2025 elections, the study will go beyond elections that have already passed to try and predict preliminary results for upcoming elections. With the agent-based model, a possible question of interest would be: “If the presidential elections were to happen at this moment, who would be the winners?”.  

To try and answer this question, recent tweets will be gathered on\\
prospecting presidential candidates based on existing poll and/or survey data in real-time. Using a similar method as in simulating the 2025 midterm elections, the simulation will now try to predict potential winners if the presidential elections were to happen this year. 