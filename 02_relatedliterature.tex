\chapter{REVIEW OF RELATED LITERATURE}
The review of related literature of the research examines existing studies grouped according to the following discussion points: the importance of sentiment analysis with transformer models like BERT, especially in the context of how elections are reflected on social media; the development of RoBERTa and XLM-RoBERTa in classifying sentiments of social media posts; defining what Agent-based Modeling is and how it can be used to enhance transformer models; and how social media has become a critical tool for political engagement and in building the general public’s sentiment.

The sentiment analysis subsection discusses its definition and how it is essential in analyzing social media engagement. Next, tools used for analyses will be discussed, especially the transformer model Bidirectional Encoder Representations for Transformers (BERT)-- its architecture, its descendants like RoBERTa, how effective BERT is for sentiment analysis using various studies as evidence, and the capabilities of XLM-RoBERTa. Lastly, the Social Media and Elections subsection discusses how social media shapes the general public, especially in the context of Philippine politics. 

\section{Sentiment Analysis for Social Media and Elections}
According to Liu [2012], the study of people's views, sentiments, assessments, appraisals, attitudes, and emotions about goods, services, organizations, people, problems, events, subjects, and their characteristics is commonly referred to as sentiment analysis or opinion mining \cite{Liu-2012}. With the explosive growth of social media, it has become a hotspot of opinions, shaping our decisions, especially in an important political event like elections. In the field of social computing, election seasons are one of the widely researched topics, especially on how the interaction in social media affects society in terms of making decisions on who to vote for. With the recent rise in popularity of many large language models (LLMs) like ChatGPT, LLMs have also been considered to perform sentiment analysis tasks. LLMs have been measured and evaluated to have satisfactory performance in simpler tasks, lag behind in more complex tasks requiring structured sentiment information, and have a potential when annotation resources are limited \cite{Liu-2023}.

There are examples of studies using sentiment analysis to analyze social media activity. In a study by Macrohon, et al. [2022] and Demillo, et al. [2023], they used the Naïve Bayes classifier, a probabilistic learning method, to determine the probability of a tweet belonging to the best class—applicable in determining the polarity of a post \cite{Macrohon-2022,Demillo-2023}. Then, previous studies showed the usage of bidirectional encoder representation from transformers (BERT) models, modified to handle emojis and Tagalog language tweets. Aquino, et al [2025] introduced the emotion-infused BERT-GCN model for sentiment analysis, which includes emoji semantics into the models, treating them as sentiment representation \cite{Aquino-2025}; meanwhile, Cruz, et al. [2022] used the RoBERTa-tagalog-cased model to get the vectorized version of Tagalog embeddings, essential to map echo chambers on Twitter via K-Means modeling \cite{Cruz-2022}. Lastly, the Support Vector Machines (SVM) Classifier model was used by Demillo, et al. [2023] to handle binary classification of data, classifying them as either a negative or positive sentiment \cite{Demillo-2023}.

For reasons discussed more in-depth in the next section, BERT was chosen for the study’s methodology given its capabilities of performing nuanced analyses and classification of social media posts.

\subsection{Development Pipeline of BERT, RoBERTa, and XLM-RoBERTa}
Recent developments in devising models for NLP tasks have ensured that models are updated to be more context-aware, being able to provide a more holistic and nuanced analysis of certain texts. One such model is BERT, short for Bidirectional Encoder Representations from Transformers (referred to henceforth as BERT). Developed by the Google AI Language Laboratory, the main advantage provided by BERT is its ability to analyse text in a bidirectional manner, as opposed to more traditional machine learning models, such as GPT, which only analyse text left-to-right or vice versa \cite{Koroteev-2021}. Bidirectional analyses of text ensures that BERT is able to capture not only the sentiments of text, but do so in such a manner that the model is able to detect certain nuances, such as sarcasm or irony \cite{Dong-2020}.

BERT’s architecture is built on transformers, an architecture of neural networks that uses a combination of recurrent and convolutional networks \cite{Koroteev-2021}.

BERT is primarily pre-trained in two phases: first, using a large dataset of unlabeled data, then second; a smaller set of labeled data, usually for fine-tuning the BERT model according to some NLP task. One such NLP task is Sentiment Analysis \cite{Koroteev-2021}. In pretraining, BERT operates on two main objectives. The first is the Masked Language Model (MLM henceforth). A random sample of tokens in the input sequence is selected and replaced with a special mask token [MASK]. The objective is then for the BERT model to be able to predict what these masked tokens are. Next is Next Sentence Prediction (NSP), a binary classification task. The goal is for the model to be able to predict whether two text segments follow each other. Both positive examples (consecutive sentences from the training set) and negative examples (pairs of segments from different documents) are provided and are sampled with equal probability.

In 2019, the Facebook AI research team found that BERT was “significantly undertrained”, and thus proposed RoBERTa, short for “[A] Robustly Optimized BERT Pretraining Approach”. The team sought to improve the training process of the BERT model by (1) training the model over a longer period of time, and with bigger batches of data, (2) removing the NSP objective in pretraining, and (3) dynamically applying the masking pattern applied to the training data. The results of this optimized pretraining process do show, indeed, that RoBERTa is able to either match or exceed the performance of BERT in NLP tasks, the former scoring higher than the latter in multiple NLP model evaluation tests such as GLUE, SQuAD, and RACE \cite{Liu-2019}.

As BERT and RoBERTa have seen usage in analysing large datasets of text, it is able to aid in research on social media. Social media is considered a rapidly evolving form of text widely different from more traditional text formats such as novels mainly due to the widespread usage of informal language, abbreviations, and emojis, among other elements, which can be challenging to understand without the proper context.

For one, Kumar and Sadanandam [2023] were able to use BERT and RoBERTa to classify a large dataset of some 8,225 tweets related to the Coronavirus into three general sentiments: positive, neutral, and negative. Both BERT and RoBERTa were able to perform sentiment analysis across the entire dataset, achieving high accuracies (at least 88\%), precision (at least 0.88), recall (at least 0.74 but can go as high as 0.91), and F1-score (at least 0.78 but can go as high as 0.90) \cite{Kumar-2023}. Prasanthi et al. [2023] were also able to accomplish a similar feat using both BERT and RoBERTa, performing sentiment analysis on large social media datasets with extremely high accuracies, these accuracies only improving with each succeeding epoch. BERT was able to achieve a base accuracy of 95.10\% on the first epoch, which only increased to 99.16\% on the tenth epoch. Similarly, RoBERTa was able to achieve a base accuracy of 99.53\%, with a final accuracy of 99.70\% on the tenth epoch \cite{Prasanthi-2023}.


As mentioned earlier, BERT and RoBERTa are able to capture nuances such as sarcasm and irony in texts. Detecting sarcasm, in particular, has proven to be a highly challenging NLP task as a sarcastic statement implies a negative sentiment whilst seemingly conveying a positive one surface-level. Nevertheless, Dong et al. were able to train RoBERTa on a dataset of posts from Reddit and X (formerly Twitter) to give it the ability to detect sarcasm in a given text, with an F1 score of 80.2 \cite{Dong-2020}.

These studies illustrate the importance of RoBERTa and BERT in the context of sentiment analysis on highly informal and nuance-laden texts such as social media posts. 

Since RoBERTa’s release, there have been updated revisions of the model that further increase RoBERTa’s performance on certain NLP tasks. Conneau et al. [2020] released a version of RoBERTa that is also able to handle texts in languages other than English but has stronger gains than the previous models on classification, sequence labeling and question answering. XLM-RoBERTa, short for Cross-lingual Model RoBERTa (referred to as XLM-R henceforth), is trained with some 2.5 terabytes of data using texts on 100 languages, and trained using the MLM objective \cite{Conneau-2020}.

The team then evaluated the model, alongside other versions of BERT, in different tests. Firstly, the XLNI, short for the Cross-lingual Natural Language Interface, is a dataset containing training and testing datasets in 15 languages. The goal of the dataset is to evaluate a model’s cross-lingual transfer from English to another language. XLM-R was able to outperform mBERT (multilingual BERT) in this test, with an advantage of around 10\% in terms of per-test accuracy.

Next is the Named Entity Recognition test, which evaluates not only cross-lingual transfer, but also the model’s performance per-language as well as multilingual learning ability. Also included are the Cross-lingual Question Answering test and finally the GLUE benchmark. Again, XLM-R outperforms mBERT on all tests, and was also shown to be able to effectively model low-resource languages such as Swahili and Urdu \cite{Conneau-2020}.

Other studies have been published since the release of XLM-R showing its prowess in processing multilingual texts, and outperforming other models in the same tasks. Azadi et al. [2025], for example, trained both XLM-R and GPT 3.5 to classify a bilingual dataset of tweets (composed of English and Spanish tweets) through two tasks. The first task was to determine whether or not the tweet has sexist content, and the second was to determine what type of textual content the tweet has with regards to sexism (if the tweet contained purposively sexist content, was reporting a sexist situation, or was condemning certain sexist behaviors). XLM-R was shown to outperform GPT 3.5 on both tasks: in Task 1, XLM-R and GPT scored an over F1 score of 0.78 and 0.71, respectively; while in Task 2, XLM-R scored 0.48 as opposed to GPT’s 0.43 \cite{Azadi-2025}.

\section{Simulating Through Agent-Based Modeling}
Analyzing social phenomena does not stop at merely analyzing the sentiments behind social media posts – with sufficient data, machine learning models can be used to create models of certain social actors and simulate the different interactions that take place between them. For this, Agent-Based Modeling is necessary. Agent-Based Modeling (ABM henceforth) is a computational model that simulates the actions and interactions of autonomous individuals or “agents \cite{Macal-2009}.” Macal and North [2009] define an agent as an autonomous decision-making entity, each of which is self-contained and possessing a set of characteristics as well as behaviors that the agent can perform. Agents are required to interact with each other through an environment, as interactions create changes to their respective states, imitating an iterative learning process \cite{Macal-2009}. Thus, such a method of modeling helps analyze social events at a large scale.

\subsection{Linking ABM with Social Networks and Social Media}
Recent studies have shown that utilizing ABM can help learn about the spread of information on social media \cite{Fan-2018,Chen-2019,DiCarlo-2021,Coscia-2022}. As social media consists of a user interacting with others, it forms a “network” of interactions between them. This network becomes the basis of how ABM can be used to study user behavior as well as the flow of information within a social media platform in a specific time period.

Past studies have delved into studying online social media phenomena using ABM. Chen [2019], for example, created an ABM to investigate the process of information diffusion in online social networks. Chen [2019] defines information diffusion as the spread of information; and efficient diffusion means widespread awareness of certain events.

A similar study \cite{Coscia-2022} was used to simulate information diffusion in social media platforms, taking into account that users might have different sociopolitical views from one another. Coscia and Rossi [2022] used ABM to study the phenomenon of polarization on social media by defining an environment meant to mirror social media, as well as agents who operate in said environment. Agents assumed the form of one of two categories: either Users with personal accounts, or News Sources with official accounts. Users are able to choose from the following actions: either reshare or flag a news item post depending on the polarity between the user and post, change their polarity, and “unfriend” and/or “unfollow” other social media users. Through a series of simulations performed through ABM, Coscia and Rossi [2022] were able to glean valuable insights about how social media users act with regards to emotionally-charged situations such as political posts, such as how sharing such posts can lead to polarization among online spaces, and how minimizing conflicts on social media might actually lead to increased polarization online.

\subsection{Linking LLMs with ABM}
Large Language Models (LLMs) with their human-like reasoning and decision-making have opened new avenues to enhance ABM’s simulations of social phenomena. Gao et. al [2024] discussed a promising foundation for simulations in ABM, especially simulations that require sophisticated cognitive abilities, such as heterogeneity and personalization of agents’ internal states and behaviors, and they have adaptive learning and evolution. However, ABM poses challenges such as computational expenses, robustness, and ethical risks. It was used across multiple domains, especially in the social domain, where there are studies that used a combination of LLMs and ABM to study social networks, especially in simulating emotions, attitudes, and information propagation in online social networks when discussing current issues that cause extreme emotions \cite{Gao-2024}.

In recent years, there have been studies addressing the combination of LLM and ABM. They use decoder models like GPT to generate interactive behaviors in the simulated social network environment, which in turn updates the agents and environment \cite{Gao-2025, Lan-2024, Piao-2025}. This methodology was applied in tackling political biases and detecting stances. The combination of two machine learning models has helped Piao et. al [2025] design and implement a social experiment that involves Bandura’s social learning theory to mitigate political biases on LLM-generated social bots \cite{Piao-2025}. Additionally, in a different study \cite{Lan-2024}, it helps them develop a multi-dimensional text analysis and reasoning-enhanced debating to determine the stance of a post, where the agents play roles through the lenses of linguistics, domain knowledge, and social media expression, and the two sides of a debate.  Therefore, based on these sources, developing a similar methodology is feasible, though certain limitations, such as the intensity of computing resources, should still be considered.

In the context of XLM-RoBERTa, there have been no existing studies on its interaction with ABM. Yet, it has the potential to become a unique advantage in tackling multilingual social dynamics and being an encoder transformer model that classifies texts. Therefore, this research gap is what this study aims to tap into regarding how being an encoder model with cross-lingual properties can help develop agents to create a simulation of Philippine social media during an election season.


\section{Social Media Use in the Elections}
To properly ground our study and simulation in real-world phenomena, it is important to note the different ways in which social media has been used throughout past election periods and how it has been taken advantage of by politicians.

Over the years, social media has become the first reference of the voters when it comes to perceiving political content and eyeing political information, political groups, and political parties \cite{Campanero-2021}. Tapsell’s [2020] analysis brings attention to an interview with Nic Gabunada, Duterte’s ‘campaign friend’, where he says Facebook became vital to their campaign after realizing that 45\% of Filipinos are on Facebook, via mobile phone, and that their goal for the campaign was to maximize awareness \cite{Tapsell-2020}. Contractor et al. [2015] also found that, alongside holding discourse and reactions, social media provides information ahead of traditional news sources by a few hours \cite{Contractor-2015}.

\subsection{Public Opinion}
Tapsell’s [2020] paper reveals how social media is used to encourage citizens to be more active online in supporting a candidate \cite{Tapsell-2020}.

As observed by Sinpeng et al [2020], despite Duterte’s unprofessional online presence, his supporters are committed and constantly rallied to his defense against the criticism of other candidates \cite{Sinpeng-2020}. Tapsell’s [2020] interview with Jonji Gonzales, a PR professional from Visayas, reveals that any form of discourse that engages with content about a political figure is a form of support, especially in cases where there’s information to correct or clarify. According to the interview, this is how the average Filipino becomes a ‘keyboard warrior’ for the candidate \cite{Tapsell-2020}.

\subsection{Voter Preference}
Student voters give importance to political attributes that reflect competencies such as profession, experience, accomplishments, and priorities \cite{Anabo-2021}. To see and verify the qualities they are looking for, social media helps voters evaluate a leader’s current and future service to their community and people by making (political) information easily accessible \cite{Campanero-2021}.

Almarez and Malawani’s [2016] study found that 44\% of their respondents indicated that their presidential preferences were influenced by social media and 75\% of their respondents indicated that social media is a determining factor in the process of presidential campaign as a channel of campaign information. Having open access to political information at any time allows for change in political opinions and preferences in voters \cite{Almarez-2016}.

Other factors that guide voter behavior are “social identity, family voting, gender differences, ideology and emotions” \cite{Qorri-2018}.
